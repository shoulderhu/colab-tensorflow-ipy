{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTPU_05_Network_Training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "R2OeoykwQeoh",
        "QXEsXNIo7WP_",
        "EJKmuVpAUoK3",
        "E2P3pYC9y4rA",
        "JwN54SA-zIyt",
        "R7_3mtfZ53em",
        "UcWhhEgi7so0",
        "I3ov7Eid70kr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoulderhu/colab-tensorflow-ipy/blob/master/NTPU_05_Network_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8xxyMMi6WKk",
        "colab_type": "text"
      },
      "source": [
        "# Lab 5: Training Techniques and ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2OeoykwQeoh",
        "colab_type": "text"
      },
      "source": [
        "## Part 0: Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Mm6XzYJz3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1dt8p9A6SXW",
        "colab_type": "code",
        "outputId": "1c8cfd33-9c78-4680-cab3-ab1886e2e00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install -U tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cTLAnfH64hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0-preview is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXEsXNIo7WP_",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Activation Functions\n",
        "\n",
        "Let's list all the activation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW83bejZ7VrB",
        "colab_type": "code",
        "outputId": "7463b11f-9606-4c87-f26d-3e5dfa7a8a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deserialize',\n",
              " 'elu',\n",
              " 'exponential',\n",
              " 'get',\n",
              " 'hard_sigmoid',\n",
              " 'linear',\n",
              " 'relu',\n",
              " 'selu',\n",
              " 'serialize',\n",
              " 'sigmoid',\n",
              " 'softmax',\n",
              " 'softplus',\n",
              " 'softsign',\n",
              " 'tanh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzShsuatypOJ",
        "colab_type": "text"
      },
      "source": [
        "Certain advanced activations are treated as layers in Keras. For these, do not specify any specific activation for the preceding layer. Simply add these advanced activations as a layer after a normal layer in your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRXaIiYfx69T",
        "colab_type": "code",
        "outputId": "c008920d-a100-4d82-a49e-bd4e69750408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJKmuVpAUoK3",
        "colab_type": "text"
      },
      "source": [
        "### Softmax\n",
        "\n",
        "We've used the softmax activation many times now without explaining what it is. So let's talk about it now. Let's say we have a *k* class classification problem. For multinomial classifcation problems, we often use the softmax activation function to calculate the probability that an input belongs to a certain class, p_k. \n",
        "\n",
        "The way softmax works is, for each class, we will have a score:\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1CN_oTjvwxTU_Nu4y1W8bipFv46UhEHmx)\n",
        "\n",
        "If you look at this closely, the score is just the weight multiplied by the input (so basically just what the neuron does before activation).\n",
        "\n",
        "Now, the probability that the input belongs to class *k* is:\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1rSxk2Gp-VE2BFE_dzHtBRi8w-NushF8Z)\n",
        "\n",
        "where *K* is the total number of classes. So basically you divide the exponential score of this class by the sum of all the output exponentials of each class. This is different than, say, the linear ratio between class *k*'s score and the sum of all the scores. Namely, the softmax function makes the probability of the higher scored classes **further** apart from the ones with lower scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2P3pYC9y4rA",
        "colab_type": "text"
      },
      "source": [
        "### Leaky ReLU\n",
        "\n",
        "Let's revisit the fashion MNIST problem using leaky ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmU6ygDSaCR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the leaky relu activation function\n",
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "def relu(z):\n",
        "    return np.where(z < 0, 0, z)\n",
        "  \n",
        "def leaky_relu(z, alpha=0.01):\n",
        "    return np.maximum(alpha*z, z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQnWneax12Tz",
        "colab_type": "code",
        "outputId": "e800e766-d827-4868-bcd5-0ced27f8daef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
        "plt.grid(True)\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.5, 4.2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEMCAYAAAALXDfgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUvEWEUlBKt4iIilIxVtEJAX9fxK+PjsDJlloAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVVO9mJ4x-CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXCHlTRpyAfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_OOV2lpyBc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN3zy3hYyC2v",
        "colab_type": "code",
        "outputId": "cc7a1458-991b-4c85-e38e-cbb2180ab81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 16:29:38.266940 140483582592896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 4s 77us/sample - loss: 1.2810 - accuracy: 0.6253 - val_loss: 0.8872 - val_accuracy: 0.7192\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.7957 - accuracy: 0.7371 - val_loss: 0.7128 - val_accuracy: 0.7676\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.6818 - accuracy: 0.7721 - val_loss: 0.6365 - val_accuracy: 0.7902\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 4s 69us/sample - loss: 0.6222 - accuracy: 0.7934 - val_loss: 0.5898 - val_accuracy: 0.8082\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.5832 - accuracy: 0.8067 - val_loss: 0.5584 - val_accuracy: 0.8166\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.5553 - accuracy: 0.8165 - val_loss: 0.5358 - val_accuracy: 0.8248\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.5341 - accuracy: 0.8218 - val_loss: 0.5177 - val_accuracy: 0.8282\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.5174 - accuracy: 0.8271 - val_loss: 0.5018 - val_accuracy: 0.8374\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 4s 68us/sample - loss: 0.5038 - accuracy: 0.8302 - val_loss: 0.4901 - val_accuracy: 0.8378\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 4s 67us/sample - loss: 0.4926 - accuracy: 0.8326 - val_loss: 0.4830 - val_accuracy: 0.8394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwN54SA-zIyt",
        "colab_type": "text"
      },
      "source": [
        "### SELU\n",
        "SELU is a scaled ELU activation function. It's special because for a network consisting of purely dense layers, the SELU activation helps the outputs *self-normalize*. That means, the output will preserve mean 0 and std 1 during training, which automatically deals with the vanishing gradient problem. Sufficiently deep dense nets will therefore work nicely with SELU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjYqyjuE1Iis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.special import erfc\n",
        "\n",
        "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
        "# (see equation 14 in the paper):\n",
        "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLxJaw4vavt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the elu and selu activations\n",
        "def elu(z, alpha=1):\n",
        "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
        "  \n",
        "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "    return scale * elu(z, alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ouYRPe2Cm7",
        "colab_type": "code",
        "outputId": "5fc41769-cec4-4a73-eef2-8c3db83e884b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [-1, -1], 'k--')\n",
        "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "plt.grid(True)\n",
        "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
        "plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEOCAYAAABsJGdEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPKz4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6VJR4Pt2G2i",
        "colab_type": "code",
        "outputId": "7eed6030-502b-4623-ae63-99c5ddc00027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
        "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "plt.grid(True)\n",
        "plt.title(\"SELU activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEMCAYAAAAh7MZPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4FUXa9/HvDWFHiYDGHZxxXxA1\n6uiMmnG5XF4dN9yXh0ElwugjCuOKIyruMoOKoCCIgooI4iivzusax30MGteRRQVxQVkMkhBISOr9\no07M4ZCQQPqkzvL7XFdf6ZzudN+n0rlPpbq6ypxziIhIZmoVOgAREUkeJXkRkQymJC8iksGU5EVE\nMpiSvIhIBlOSFxHJYErykvbMbL6ZDWmB8wwzs09b4DytzOxBM1tqZs7MCpJ9zkbimWhmM0PGIBtP\nST6DmNnmZjY6lvRWm9mPZvaKmR0Vt09RLHEkLlPi9nFm1qeBc/Q1s7IGtjX4c1FYT5LdHxgd4Xl6\nxt5LfsKmu4HDojrPehwH/Bk4AdgKeLsFzomZFcTed/eETZcB57ZEDBK9nNABSKSmAx2BC4B5wBb4\npNQtYb+HgWsTXqtIenRJ4pxb3ELnKQPq/YCL2I7AD865FknujXHOLQ8dgzSDc05LBixALuCAIxvZ\nrwgY1cg+DujTwLa+QNmG/lxs+zHAG8DPwDLg/wG7JeyzNfAYsBRYCZQAf4yd1yUsfWM/Mx8YElt/\nHJiecMxWwELgiqbEUc95imKvDwM+TTju9bFjrwY+AU6M294z9vOnAi/F3s/nwFHrKaOJCeee39Dv\nLbbvzITf7WjgVmAJ8BP+v49Wcfu0jW1fEIv5K+B/42KNXyY2cJ52wEjgR2AV8C7wh7jtBbGfPwJ4\nL/a+i4F9Q/+dZOOi5prMUVvL/JOZtQ8dTAM64ZPDAfhEsBx4zszaAphZJ+B1fMI5CdgLuCn2s08C\nI4DZ+CaMrWKvJZoM/B8z6xL32mGx/Z9oShyx18F/GGwFnNLA+7kM+CtwVSzWGcDTZtY7Yb9bgHuB\nvYH3gSlm1nk9x7wJ+DZ27v0b2K8h5wBrgIOBS4BBwBlx2x8BzgeuAHbD/9dXiv+gOjW2zx6xc1/W\nwDnujB2zH7AP/sPtX2a2VcJ+twFXA/viP7QfMzPbwPcjzRX6U0ZLdAv+j3QZvnb1Dr4Wd2DCPkVA\nJXUfCrXLwLh9klKTr2f/TkA1sVogcBGwAujewP7DiKtJx70+n7qafA6+hnlB3PaHgBc3II6esfeS\nv77zA98Bf6unfCcnHKcwbvs2sdf+sJ54hhCrwScctyk1+XcS9nkJeCi2vlPs3Mc0cN6C2PbuDZ0n\nVlaVwPlx21sDXwLDE45zdNw+v4+9tm3ov5NsW1STzyDOuen45o4TgBfwtbl3zSyx/f1JoHfC8liy\n4zOz35rZ42b2pZn9gk/GrYDtY7vsA3zsnFuysedwzq3Bv79zYudsh//wm7wBcTTlvWyKL+u3Eja9\nCeye8NrHcevfx75u0dRzbaCPE77/Pu5c+wA1wGvNOP5vgTbEvW/nXDW+UhHyfUsDdOM1wzjnVuFr\nby8BN5nZQ8AwM7vbOVcZ2225c27eRp7iF6CDmbVxzlXVvmhmubXHXs/PzsQ3QxTia8Fr8G3Ubdfz\nMxtjMvCOmW0DHBg7/tMtGEfi0K6/lpNzzsVaLDa0glUDJDZ1tKlnv6qE791GnGtjNfi+47apYtnC\nVOCZ73P8h3lU7fSz8dfNPgmv7xu3fR1m1g3YFbjVOfeyc+6/wCasXdH4EOhVTxe+WpX4poH1cs79\nB9+76Cx8jf6fzveMaWoctR+GDZ7LOfcLvnb6+4RNf8CXedQW49vJ4+29gccowf/u/tjA9kbfN75Z\nppK4921mrYGDSM77lmZSTT5DxJLXU8AE/L/JK4B84ErglVhSqtXRzLZMOESlc25Z3Pc967mB+JVz\n7jMzexF4yMyuwP/R7wzcA0x1zn3TQIg/43t8XGRmC/Ft03fha9G1HsffqPunmV2Nr2XvCaxwzr2G\nb3vvYWb7At/EXl/dwPkeAy7Et4vH3zhtShw/4buUHm1m84FVrv5uhHfh/1uaC8zC9yU/hLoPvCi9\nCow0sz/hP0gLge3wZdIkzrk5ZjYV/7u7DPgA2Bbo6ZybhO9x4/A3rp8DKmo/HOOOUW5mY4A7zGwJ\n8DVwOZBHhM8qSIRC3xTQEs2C79Z2K773xs/4bmtzgb8DXeP2K2LdrnIOeDNun/q2O+D42PZcfFKf\nFzvPHOAOoHMjMR4OfIq/MfwpcDT+pm/fuH22xbepl8aO/SFQEPcep8XeX71dKOOO85vYPj8CORsR\nx4X4D5JqmtaFshLfy+SkuO09qf8GbmNdTeu78doGuB//AbUEuJH6b7w2dnO2Hb53zHf4LpRfApfE\nbb8e+AHfPDRxPceo7UK5moa7UHZvrCy0JH+x2C9AREQykNrkRUQymJK8iEgGU5IXEclgSvIiIhks\neBfK7t27u549ewaNoby8nE6dOgWNIVWoLLzZs2dTXV3N7rsnPsSZnVLhuigvh9mzwTnYYQfo2jVU\nHOHLAmDWrFlLnHObN7Zf8CTfs2dPiouLg8ZQVFREQUFB0BhShcrCKygooLS0NPi1mSpCXxc//AD7\n7ecT/GWXwciRwUIJXha1zGxBU/ZTc42IpLTKSjjtNJ/oDz0U7rordETpRUleRFLa4MHw1luwzTYw\ndSq0qW/EHmmQkryIpKxHH4VRo6BtW5g+HfLyQkeUfiJN8mY22cx+MLNfzGyOmV0Y5fFFJHt88AEU\nFvr1++6DAw8MG0+6iromfxt+sKNNgT8Bw81sv4jPISIZbskSOOUUWLUKLrwQ+vcPHVH6ijTJO+c+\nc3WjAtYOavXbKM8hIpmtuhrOOgsWLIADDvDNNbLxIu9CaWaj8VPEdcCPIPh8Pfv0B/oD5OXlUVRU\nFHUYG6SsrCx4DKlCZeGVlpZSXV2tsohpyeti7Njf8PLL25ObW8ngwbN4552GRpMOI93+RpIyCmXc\nJAIFwB0ubgahRPn5+S50X+RU6feaClQWXm0/+ZKSktChpISWui6mT4c+faB1a3j5ZUjFSzFV/kbM\nbJZzLr+x/ZLSu8Y5V+2cexM/NviAZJxDRDLL559D375+/a67UjPBp6Nkd6HMQW3yItKI5cvh5JOh\nrMy3xw8aFDqizBFZkjezLczsTDPrbGatzexo/Bybr0R1DhHJPDU1cP75MGcO9OoF48aBJU5ZLhst\nyhuvDt808wD+w2MBMMg592yE5xCRDHPLLfDss5CbC08/DSkw9ldGiSzJO+cWA4dFdTwRyXzPPw83\n3OBr7o8/Dr9V427kgo9CKSLZad48OOccP7LkzTfDsceGjigzaewaEWlx5eX+idbSUjjxRLj22tAR\nZS4leRFpUc75oQo++QR23hkeeQRaKRMljYpWRFrUyJEwZQp07gzPPANduoSOKLMpyYtIi3ntNfjr\nX/36I4/AbruFjScbKMmLSItYuBDOOMMPQHb11b5NXpJPSV5Ekm7VKjj1VFi8GI46CoYPDx1R9lCS\nF5Gkcg4uuQTefx969oQnnvADkEnLUJIXkaQaNw7Gj4f27f0Trd26hY4ouyjJi0jSvPuur8UDjB0L\n++wTNp5spCQvIkmxaJFvh6+qgksvhfPOCx1RdlKSF5HIVVXB6afD99/DIYfAiBGhI8peSvIiErkh\nQ+CNN2DrrWHqVGjTJnRE2UtJXkQiNXky3HuvT+zTpsGWW4aOKLspyYtIZEpKoH9/v37vvXDQQWHj\nESV5EYnIsmV+Cr+KCujXDwoLQ0ckoCQvIhGorvZzs86fD/n5cP/9msIvVSjJi0izXX89vPgidO8O\n06f7B58kNSjJi0izPP003HabHxN+6lTYfvvQEUk8JXkR2Wj//S/8z//49TvvhD/+MWw8si4leRHZ\nKL/84m+0lpX5IYSvuCJ0RFIfJXkR2WA1Nb4GP3s27LmnH4BMN1pTk5K8iGyw22/3U/fl5sKMGdCp\nU+iIpCFK8iKyQf71Lxg61NfcH3sMdtwxdESyPjmhAxCR9PHVV3D22X4ikBtvhOOOCx2RNEY1eRFp\nkpUr/Y3Wn3+GE07wtXlJfUryItIo5+Cii+Djj2GnnWDSJN8vXlKffk0i0qjp07fh8cf9DdYZM6BL\nl9ARSVMpyYvIer3+OowZ4++uPvww7LFH4IBkgyjJi0iDvv3Wz/BUU2NceSWcdlroiGRDKcmLSL1W\nr/ZztP70E+y33zJuuSV0RLIxIkvyZtbOzMab2QIzW2FmJWZ2bFTHF5GWdeml8J//QI8ecP31/yVH\nHa7TUpQ1+RxgIXAY0AUYCkw1s54RnkNEWsC4cX5p396PMtmlS1XokGQjRZbknXPlzrlhzrn5zrka\n59xM4Gtgv6jOISLJ9957cMklfv2BB2DffcPGI82TtH/AzCwP2Bn4rJ5t/YH+AHl5eRQVFSUrjCYp\nKysLHkOqUFl4paWlVFdXZ11ZLFvWhsLCfCor23HSSd/Ro8dciop0XcRLt7Iw51z0BzVrA7wAfOmc\nW+9Mj/n5+a64uDjyGDZEUVERBQUFQWNIFSoLr6CggNLSUkpKSkKH0mKqquCoo3yXyd//Hl59Fdq2\n9dt0XdRJlbIws1nOufzG9ou8d42ZtQImAZXAJVEfX0SS48orfYLfait46qm6BC/pLdLmGjMzYDyQ\nBxznnNPdGpE08PjjMHIktGkD06b5RC+ZIeo2+THAbsCRzrmKiI8tIknw0Udw4YV+feRIOPjgsPFI\ntKLsJ98DKAR6A4vMrCy2nBPVOUQkWsuW+ZElKyqgb18YMCB0RBK1yGryzrkFgCYAE0kT1dVwzjnw\n9de+m+To0ZrCLxNpWAORLDVsmJ/lqXt3/8BThw6hI5JkUJIXyULPPAPDh/sx4adM8UMXSGZSkhfJ\nMl98Aeef79dvvx2OOCJsPJJcSvIiWWTFCn+jdcUKP2zwkCGhI5JkU5IXyRLO+R40X3zhJ/6YMEE3\nWrOBkrxIlrjjjtoRJf0Ufp07h45IWoKSvEgWePFFuO46vz55sp+MW7KDkrxIhvv6azjrLKipgRtu\ngOOPDx2RtCQleZEMtnIlnHKKf7L1+OPhb38LHZG0NCV5kQzlHBQWQkkJ7LgjTJrk+8VLdtGvXCRD\njRrl2987dvQ3WnNzQ0ckISjJi2SgN96AK67w6w8/DHvuGTYeCUdJXiTDfPedf9BpzRr/sNPpp4eO\nSEJSkhfJIKtXQ58+8OOPcPjhcNttoSOS0JTkRTLIZZfBu+/C9tv7gcdyop4WSNKOkrxIhhg/Hh58\nENq1g+nTYfPNQ0ckqUBJXiQDvP8+DBzo18eMgfz8sPFI6lCSF0lzP/3kH3iqrPTT9/35z6EjklSi\nJC+SxtasgTPOgG+/hYMO8hNxi8RTkhdJY1dfDUVFsOWWMG0atG0bOiJJNUryImlqyhQYMcL3oHnq\nKdh669ARSSpSkhdJQx9/DBdc4Nf/8Q/4wx/CxiOpS0leJM38/LO/0bpypZ+r9S9/CR2RpDIleZE0\nUlMD554LX34J++wDDzygKfxk/ZTkRdLIjTfC889Dt25+Kr8OHUJHJKlOSV4kTTz7LNx0kx8T/okn\noGfP0BFJOlCSF0kDc+bAeef59VtvhaOOChuPpA8leZEUt2IFnHwy/PILnHoqXHll6IgknSjJi6Qw\n56BfP/j8c9h9dz8BiG60yoZQkhdJYXfd5Z9k3XRTf6N1k01CRyTpJtIkb2aXmFmxma02s4lRHlsk\n27z0ElxzjV+fNAl22SVsPJKeop5S4HtgOHA0oM5dIhtp/nw46yzfL/766+FPfwodkaSrSJO8c+5p\nADPLB7aN8tgi2aKiwj/RunQpHHccDBsWOiJJZ0EmBzOz/kB/gLy8PIqKikKE8auysrLgMaQKlYVX\nWlpKdXV1i5eFc3D77bvy4YdbsvXWFVx88Sz+/e81LRpDfXRd1Em3sgiS5J1zY4GxAPn5+a6goCBE\nGL8qKioidAypQmXh5ebmUlpa2uJlcf/98OKL0LEjvPBCB3r1So2Rx3Rd1Em3slDvGpEU8eabMGiQ\nXx8/Hnr1ChuPZAYleZEU8P33cNppfqanK66AM88MHZFkikiba8wsJ3bM1kBrM2sPrHHOhW9UFElR\nlZU+wS9aBAUFcMcdoSOSTBJ1TX4oUAFcDZwbWx8a8TlEMsrll8Pbb8O228KTT/qZnkSiEnUXymHA\nsCiPKZLJJk6E0aP93KxPPw1bbBE6Isk0apMXCaS4GC6+2K+PHg377x82HslMSvIiASxe7B94Wr0a\nCgvr5msViZqSvEgLW7PG955ZuBB+9zu4557QEUkmU5IXaWHXXguvvgp5eX6EyXbtQkckmUxJXqQF\nTZ3qhw/OyYGnnoJttgkdkWQ6JXmRFvLpp34CEIARI+CQQ8LGI9lBSV6kBZSW+in8ysvh3HPh0ktD\nRyTZQkleJMlqavwk3PPmQe/e8OCDmsJPWo6SvEiS3XwzzJwJm23mH3jq2DF0RJJNlORFkmjmTD/p\nhxk88QTssEPoiCTbKMmLJMncub79HeCWW+Doo8PGI9lJSV4kCcrK/I3W5cv916uvDh2RZCsleZGI\nOeeHKfjsM9h1Vz8ImW60SihK8iIRGzHCP/S0ySYwYwZsumnoiCSbKcmLROiVV+Cqq/z6o4/6mrxI\nSEryIhFZsADOOMP3i7/uOjjppNARiSjJi0SiogJOPRWWLoVjjoEbbwwdkYinJC/STM7BwIEwaxb8\n5jfw2GPQunXoqEQ8JXmRZnrgAd+DpkMH/0Rr166hIxKpoyQv0gxvvw2XXebXH3oI9t47bDwiiZTk\nRTbSDz9Anz5QVQWDBsHZZ4eOSGRdSvIiG6GyEk47zSf6ww6DO+8MHZFI/ZTkRTbC4MHw1lt+Zqcn\nn4Q2bUJHJFI/JXmRDfToozBqFLRtC9On+7laRVKVkrzIBvjgAygs9OujRsGBB4aNR6QxSvIiTbRk\nCZxyCqxaBRdd5BeRVKckL9IEa9bAWWf5oQsOOADuuy90RCJNoyQv0gRDh8LLL8MWW/h2+HbtQkck\n0jRK8iKNmDYN7rjDD1UwdSpsu23oiESaTkleZD0+/xz69vXrd9/t+8SLpJNIk7yZdTWzGWZWbmYL\nzEzPAEraqq42TjoJysv906y1wxeIpJOciI93P1AJ5AG9gf9rZh855z6L+DwiSbdwYUeWL4devWDc\nOE3hJ+nJnHPRHMisE/AzsKdzbk7stUnAd865Bqcx3mSTTdx+++0XSQwbq7S0lNzc3KAxpAqVhVdc\nXEJ5ObRu3Zv8fGjfPnREYem6qJMqZfH666/Pcs7lN7ZflDX5nYE1tQk+5iNgnVZMM+sP9Ado06YN\npaWlEYax4aqrq4PHkCpUFl5FhQOMzTdfxapVq1i1KnREYem6qJNuZRFlku8M/JLw2nJgk8QdnXNj\ngbEA+fn5rri4OMIwNlxRUREFBQVBY0gVKgt46ik4/fQCcnJqmDfv33TqFDqi8HRd1EmVsrAmth9G\neeO1DEicl35TYEWE5xBJqqoqPz8rwJZbrlaCl7QXZZKfA+SY2U5xr+0N6KarpI0JE2DuXD/LU9eu\nq0OHI9JskSV551w58DRwk5l1MrPfAycCk6I6h0gylZfXTcC9ww7qTSOZIeqHoQYCHYCfgCeAAeo+\nKeninnv8JCD5+bD55qGjEYlGpEneObfMOXeSc66Tc25759zjUR5fJFmWLvVDFwDcfnvYWESipGEN\nRIDbboNffoGjjoIjjggdjUh0lOQl682f7ycAAdXiJfMoyUvWu/pqWL3aj0+z776hoxGJlpK8ZLV3\n3vETcbdv75tsRDKNkrxkrZoauPxyvz5kCGy/fdh4RJJBSV6y1pNPwnvvwZZbwlVXhY5GJDmU5CUr\nVVT4tniA4cOhc+ew8Ygki5K8ZKXbb4dvvvFjxdfO/CSSiZTkJet88UVdV8n77vNzt4pkKiV5ySrO\nwcUXQ2UlXHABHHpo6IhEkktJXrLKo4/C669D9+51wxiIZDIleckaS5bA4MF+/e9/h27dwsYj0hKU\n5CVrDB7sByI7/HA499zQ0Yi0DCV5yQozZvimmvbtYcwYjRUv2UNJXjLejz9C//5+/c47Yeedw8Yj\n0pKU5CWjOQcXXeTb4484Av7yl9ARibQsJXnJaA8/DM89B126+PVWuuIly+iSl4w1Zw5cdplfHzUK\nttsubDwiISjJS0ZauRL69IGyMjj9dDjnnNARiYShJC8Z6ZJL4JNPYKedYNw49aaR7KUkLxnn4Yf9\n0r49TJsGm24aOiKRcJTkJaN89BEMHOjXR4/2o0yKZDMleckYixbBCSfAqlXw5z/7RSTbKclLRqio\ngJNOgoUL4aCDfC1eRJTkJQM452vt770HPXrAM8/49ngRUZKXDHDDDX6+1k02gZkzYYstQkckkjqU\n5CWt3Xcf3Hyzf5J1yhTYc8/QEYmkFiV5SVuTJsH//q9fHzcOjjsubDwiqUhJXtLSs8/W9Z65+27o\n1y9sPCKpSkle0s4LL/ihCqqr4brr6mZ7EpF1RZLkzewSMys2s9VmNjGKY4rU55//hBNPhNWr4dJL\nfXu8iDQsqpr898BwYEJExxNZx9SpftCxqiq4/HK45x6NSSPSmEiSvHPuaefcM8DSKI4nkmjCBDjr\nLFizBq65BkaMUIIXaYqcECc1s/5Af4C8vDyKiopChPGrsrKy4DGkilQrC+fgkUd68sgjPQHo2/dr\njjpqAa+/ntzzlpaWUl1dnVJlEVKqXRchpVtZBEnyzrmxwFiA/Px8V1BQECKMXxUVFRE6hlSRSmVR\nVQWFhfDII74f/KhRMGDADsAOST93bm4upaWlKVMWoaXSdRFaupVFo801ZlZkZq6B5c2WCFKyz9Kl\nvt/7ww9Dx45+qIIBA0JHJZJ+Gq3JO+cKWiAOkV99+CGccgrMn++HKJg5E/bfP3RUIukpqi6UOWbW\nHmgNtDaz9mYWpClI0tvkyXDwwT7B778/FBcrwYs0R1RdKIcCFcDVwLmx9aERHVuyQFkZXHABnHee\nHw++Xz/49781+bZIc0VS23bODQOGRXEsyT6zZvnukXPnQrt2vv97//7qIikSBQ1rIMFUVcEtt/hJ\nPubO9SNIFhf7HjVK8CLRULu5BPHBB755pqTEf3/ppXDHHdChQ9i4RDKNavLSosrK4Kqr4IADfILf\nYQd46SW4914leJFkUJKXFuEcPP447LIL3Hkn1NT48Wc++QSOPDJ0dCKZS801knTvvgt//Su8GXt0\nbv/9/dOrBxwQNi6RbKCavCTNZ5/BySf7G6tvvukfbJowwSd9JXiRlqGavETu44/9TdQpU3yzTMeO\nMGgQXHkldOkSOjqR7KIkL5F54w24/XZ4/nn/fU4OXHwxDB0KW20VNjaRbKUkL81SVQXPPQd//zu8\n9ZZ/rUMHuOgiuOIK6NEjbHwi2U5JXjbKggUwbhyMHw+LFvnXNtvM93e/9FLo3j1sfCLiKclLk1VU\n+KaYCRP8ZNrO+dd32803y/TrB507h41RRNamJC/rVVUFr7wCTzwBM2bAihX+9bZt/XyrhYVwyCEa\nhkAkVSnJyzrKy31if+45P1nHkiV12/Lz4eyz/WiRapIRSX1K8gLA11/7JphHH92LkhJYvbpu2267\n+VEizzwTdtopXIwisuGU5LPUd9/Ba6/55dVX/SQdXjfM4MAD4YQT/LLXXmqOEUlXSvJZYPVqPxjY\ne+/VLV9+ufY+m20Ghx8OO+74BZdfvit5eWFiFZFoKclnmIoK+PxzP/DXhx/6hP7hh1BZufZ+nTvD\noYf6xH744dCrF7RuDUVFi8jL2zVM8CISOSX5NLVypa+Nz5kDn37qk/onn8C8eX4ogUS77eabYH73\nO/91zz39E6kiktn0Z56inIPFi+Gbb2DhQp+8583zMyjNnQvfflv/z7VuDbvv7tvRe/XyA4Htv7/G\njBHJVkryAVRUwI8/1i2LFvlEXpvQa5f4Hi6JcnL8hBs77QR77OET+l57wa67+nlSRURASb5ZnPMP\nB/38MyxbtvbX+PXFi+Gnn+qSeu0DRY3ZbDPYfnvYbru6hF679Oih5hYRaVzGp4mqKli1yi8VFWt/\nrV0vLu7ODz/4du6yMp+Ea7/Gryd+Xb4cqqs3PKY2bSAvz4+vnpfnl9pkXvt1u+00RICINF/wJP/D\nD/C3v/lk3NylstIv8Ym8aUl4z42Ov1Mn6NrV17prl/jvu3aFbt3qknleHuTmqt+5iLSM4En+++9n\nc/PNBQmvng4MBFYCx9XzU31jyxKgTz3bBwBnAAuB82jVirWWvLzBbLHFCdTUzOarrwqprq6iXbs2\ntGrlm0AOOWQovXodyfLlJTzzzCBat/Y3NHNy/NerrrqVgoKD+eyzt7nhhmvXOvPPP8MNN4ykd+/e\nvPzyywwfPnyd6B588EF22WUXnnvuOUaMGLHO9kmTJrHddtvx5JNPMmbMmHW2T5s2je7duzNx4kQm\nTpy4zvbnn3+ejh07Mnr0aKZOnbrO9qKiIgDuvvtuZs6cuda2iooK3nvvPQBuvvlmXnnllbW2d+vW\njenTpwNwzTXX8M4776y1fdttt2Xy5MkADBo0iJKSkrW277zzzowdOxaA/v37M2fOnLW29+7dm5Ej\nRwJw7rnn8m3CHeaDDjqI2267DYBTTz2VpUuXrrX9iCOO4Prrrwfg2GOPpaKiYq3txx9/PEOGDAGg\noKCARKeffjoDBw6kpqaGefPmrbNP37596du3L0uWLKFPn3WvvQEDBnDGGWewcOFCzjvvvHW2Dx48\nmBNOOIHZs2dTWFi4zvahQ4dy5JFHUlJSwqBBg9bZfuutt3LwwQfz9ttvc+21166zfeTI5Fx7paWl\n5ObmJvXa69ChAy+88AKQ3dfeypUrOe64dfNeY9deQ4In+bZt/YQSrVr52q0Z7LcfHHGE7wp4zz3+\ntfjtxxwDxx/vx1gZOnTt7a1a+dEQzzzTt4X367fuOQcP9k9yzp7tB9gqLS0nNzf31+0XXOAnly4p\n8VPVJdp6az9uS5s2SSwYEZEImKsdLzaQ/Px8V1xcHDSGoqKiej9Zs5HKwisoKKC0tHSd2mC20nVR\nJ1XKwsxmOefyG9tPE3mLiGQOOQu7AAADkUlEQVQwJXkRkQymJC8iksGU5EVEMpiSvIhIBmt2kjez\ndmY23swWmNkKMysxs2OjCE5ERJonipp8Dv6po8OALsBQYKqZ9Yzg2CIi0gzNfhjKOVcODIt7aaaZ\nfQ3sB8xv7vFFRGTjRf7Eq5nlATsDn61nn/5Af4C8vLxfH3UOpaysLHgMqUJl4ZWWllJdXa2yiNF1\nUSfdyiLSJ17NrA3wAvClc27dgTnqoSdeU4vKwtMTr2vTdVEnVcoisidezazIzFwDy5tx+7UCJgGV\nwCXNil5ERCLRaHONc66gsX3MzIDxQB5wnHOuqvmhiYhIc0XVJj8G2A040jlX0djOIiLSMqLoJ98D\nKAR6A4vMrCy2nNPs6EREpFmi6EK5ANA8RyIiKUjDGoiIZLDgk4aY2WJgQdAgoDt+LkFRWcRTWdRR\nWdRJlbLo4ZzbvLGdgif5VGBmxU3pb5oNVBZ1VBZ1VBZ10q0s1FwjIpLBlORFRDKYkrw3NnQAKURl\nUUdlUUdlUSetykJt8iIiGUw1eRGRDKYkLyKSwZTkRUQymJJ8PcxsJzNbZWaTQ8cSQrbP22tmXc1s\nhpmVx8rg7NAxhZDt10FD0i0/KMnX737g/dBBBJTt8/bej58XIQ84BxhjZnuEDSmIbL8OGpJW+UFJ\nPoGZnQmUAq+EjiUU51y5c26Yc26+c67GOTcTqJ23N6OZWSfgVOB651yZc+5N4FngvLCRtbxsvg4a\nko75QUk+jpltCtwEXBE6llTSlHl7M8jOwBrn3Jy41z4CsrEmv5Ysuw7Wka75QUl+bTcD451z34YO\nJFXE5u19DHjEOfdF6HhaQGfgl4TXlgObBIglZWThdVCftMwPWZPkG5ur1sx6A0cC/wgda7Jp3t71\nKgM2TXhtU2BFgFhSQpZeB2tJ5/wQ1fR/Ka+xuWrNbBDQE/jGT1lLZ6C1me3unNs36QG2IM3bu15z\ngBwz28k5Nzf22t5kbxNFtl4HiQpI0/ygYQ1izKwja9fghuB/qQOcc4uDBBWQmT2An9LxSOdcWeh4\nWpKZTQEccCG+DJ4HDnbOZV2iz+brIF4654esqck3xjm3ElhZ+72ZlQGrUv0XmAxx8/auxs/bW7up\n0Dn3WLDAWs5AYALwE7AU/4ecjQk+26+DX6VzflBNXkQkg2XNjVcRkWykJC8iksGU5EVEMpiSvIhI\nBlOSFxHJYEryIiIZTEleRCSDKcmLiGSw/w/C5mrmth0iRwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffe8tohL2UtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_1000_activations(activation):\n",
        "  np.random.seed(42)\n",
        "  Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "  for layer in range(1000):\n",
        "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "    Z = activation(np.dot(Z, W))\n",
        "    means = np.mean(Z, axis=0).mean()\n",
        "    stds = np.std(Z, axis=0).mean()\n",
        "    if layer % 100 == 0:\n",
        "      print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ApGjHK02NMA",
        "colab_type": "code",
        "outputId": "50ab47b5-99d1-45ac-9046-2111844578dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_1000_activations(selu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 0: mean -0.00, std deviation 1.00\n",
            "Layer 100: mean 0.02, std deviation 0.96\n",
            "Layer 200: mean 0.01, std deviation 0.90\n",
            "Layer 300: mean -0.02, std deviation 0.92\n",
            "Layer 400: mean 0.05, std deviation 0.89\n",
            "Layer 500: mean 0.01, std deviation 0.93\n",
            "Layer 600: mean 0.02, std deviation 0.92\n",
            "Layer 700: mean -0.02, std deviation 0.90\n",
            "Layer 800: mean 0.05, std deviation 0.83\n",
            "Layer 900: mean 0.02, std deviation 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqetlRuDzHDs",
        "colab_type": "code",
        "outputId": "d8631dd5-40e7-4d9b-8483-818e89ef8dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_1000_activations(relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 0: mean 0.40, std deviation 0.58\n",
            "Layer 100: mean 0.00, std deviation 0.00\n",
            "Layer 200: mean 0.00, std deviation 0.00\n",
            "Layer 300: mean 0.00, std deviation 0.00\n",
            "Layer 400: mean 0.00, std deviation 0.00\n",
            "Layer 500: mean 0.00, std deviation 0.00\n",
            "Layer 600: mean 0.00, std deviation 0.00\n",
            "Layer 700: mean 0.00, std deviation 0.00\n",
            "Layer 800: mean 0.00, std deviation 0.00\n",
            "Layer 900: mean 0.00, std deviation 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "786szc0J3iPL",
        "colab_type": "code",
        "outputId": "98d26f52-783d-4c05-c14b-6b2c1fb2c05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_1000_activations(leaky_relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 0: mean 0.39, std deviation 0.59\n",
            "Layer 100: mean 0.00, std deviation 0.00\n",
            "Layer 200: mean 0.00, std deviation 0.00\n",
            "Layer 300: mean 0.00, std deviation 0.00\n",
            "Layer 400: mean 0.00, std deviation 0.00\n",
            "Layer 500: mean 0.00, std deviation 0.00\n",
            "Layer 600: mean 0.00, std deviation 0.00\n",
            "Layer 700: mean 0.00, std deviation 0.00\n",
            "Layer 800: mean 0.00, std deviation 0.00\n",
            "Layer 900: mean 0.00, std deviation 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIVyyNQK1VdJ",
        "colab_type": "code",
        "outputId": "cc315412-0dbb-4094-a465-30cfd905370d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_1000_activations(elu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 0: mean 0.16, std deviation 0.79\n",
            "Layer 100: mean -0.00, std deviation 0.02\n",
            "Layer 200: mean -0.00, std deviation 0.01\n",
            "Layer 300: mean -0.00, std deviation 0.00\n",
            "Layer 400: mean 0.00, std deviation 0.00\n",
            "Layer 500: mean -0.00, std deviation 0.00\n",
            "Layer 600: mean 0.00, std deviation 0.00\n",
            "Layer 700: mean 0.00, std deviation 0.00\n",
            "Layer 800: mean -0.00, std deviation 0.00\n",
            "Layer 900: mean -0.00, std deviation 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNYxS1BL3tmJ",
        "colab_type": "text"
      },
      "source": [
        "Let's try using the SELU activation on fashion MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hELNvWWn1b6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
        "                             kernel_initializer=\"lecun_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
        "                                 kernel_initializer=\"lecun_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wg_dnno4N5l",
        "colab_type": "text"
      },
      "source": [
        "Before training it, remember to scale the inputs to mean 0 and std 1 first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho4A7qf74F_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDD_2x3n4Sps",
        "colab_type": "code",
        "outputId": "1e74215b-b188-40b8-c885-849e5d6e3c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "55000/55000 [==============================] - 34s 617us/sample - loss: 1.2710 - accuracy: 0.5080 - val_loss: 1.0708 - val_accuracy: 0.5594\n",
            "Epoch 2/5\n",
            "55000/55000 [==============================] - 29s 534us/sample - loss: 0.8509 - accuracy: 0.6779 - val_loss: 0.6995 - val_accuracy: 0.7412\n",
            "Epoch 3/5\n",
            "55000/55000 [==============================] - 30s 537us/sample - loss: 0.7195 - accuracy: 0.7356 - val_loss: 0.7018 - val_accuracy: 0.7498\n",
            "Epoch 4/5\n",
            "55000/55000 [==============================] - 30s 538us/sample - loss: 0.7286 - accuracy: 0.7386 - val_loss: 0.8595 - val_accuracy: 0.7112\n",
            "Epoch 5/5\n",
            "55000/55000 [==============================] - 29s 535us/sample - loss: 0.6805 - accuracy: 0.7522 - val_loss: 0.5807 - val_accuracy: 0.8048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZAZ_UW94cDs",
        "colab_type": "text"
      },
      "source": [
        "Let's do the same thing with ReLU to compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufMNCqUv4ail",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo-1EGAW4jzT",
        "colab_type": "code",
        "outputId": "590b47a0-d313-4b2c-c5bc-64f415a76972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "55000/55000 [==============================] - 21s 381us/sample - loss: 1.8279 - accuracy: 0.2662 - val_loss: 1.2287 - val_accuracy: 0.4560\n",
            "Epoch 2/5\n",
            "55000/55000 [==============================] - 19s 339us/sample - loss: 1.1299 - accuracy: 0.5147 - val_loss: 1.0086 - val_accuracy: 0.5574\n",
            "Epoch 3/5\n",
            "55000/55000 [==============================] - 19s 340us/sample - loss: 1.0200 - accuracy: 0.5735 - val_loss: 1.0418 - val_accuracy: 0.5538\n",
            "Epoch 4/5\n",
            "55000/55000 [==============================] - 19s 341us/sample - loss: 0.9309 - accuracy: 0.6126 - val_loss: 0.7873 - val_accuracy: 0.6586\n",
            "Epoch 5/5\n",
            "55000/55000 [==============================] - 19s 343us/sample - loss: 0.7924 - accuracy: 0.6719 - val_loss: 0.7257 - val_accuracy: 0.7084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7_3mtfZ53em",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsmIK93Z55LA",
        "colab_type": "code",
        "outputId": "1b40ed2c-31cd-4bf6-9e18-a3e6816595d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_205 (Dense)            (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "dense_206 (Dense)            (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_207 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWwuzJfW6CwG",
        "colab_type": "code",
        "outputId": "6b540a01-6d59-40df-8b6d-e7ff080bf30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bn1 = model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhEnRPF87LYH",
        "colab_type": "code",
        "outputId": "0421ce47-fd64-454f-944f-7c68e4953a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.8756 - accuracy: 0.7140 - val_loss: 0.5515 - val_accuracy: 0.8216\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.5765 - accuracy: 0.8033 - val_loss: 0.4743 - val_accuracy: 0.8434\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.5146 - accuracy: 0.8213 - val_loss: 0.4382 - val_accuracy: 0.8534\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4821 - accuracy: 0.8322 - val_loss: 0.4171 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 6s 108us/sample - loss: 0.4590 - accuracy: 0.8403 - val_loss: 0.4002 - val_accuracy: 0.8658\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4428 - accuracy: 0.8459 - val_loss: 0.3884 - val_accuracy: 0.8690\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4219 - accuracy: 0.8521 - val_loss: 0.3792 - val_accuracy: 0.8718\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4150 - accuracy: 0.8549 - val_loss: 0.3695 - val_accuracy: 0.8758\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 6s 106us/sample - loss: 0.4014 - accuracy: 0.8588 - val_loss: 0.3630 - val_accuracy: 0.8740\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 6s 106us/sample - loss: 0.3932 - accuracy: 0.8614 - val_loss: 0.3581 - val_accuracy: 0.8770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoboWrxH7jN4",
        "colab_type": "text"
      },
      "source": [
        "Let's try putting the batch normalization before the activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_a99bS97nU2",
        "colab_type": "code",
        "outputId": "cc80dc77-c302-4c1d-89e1-45a1b868434a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(100, use_bias=False),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.8618 - accuracy: 0.7093 - val_loss: 0.5659 - val_accuracy: 0.8084\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 6s 107us/sample - loss: 0.5809 - accuracy: 0.8008 - val_loss: 0.4832 - val_accuracy: 0.8350\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 6s 108us/sample - loss: 0.5161 - accuracy: 0.8199 - val_loss: 0.4463 - val_accuracy: 0.8474\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4850 - accuracy: 0.8301 - val_loss: 0.4255 - val_accuracy: 0.8550\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4580 - accuracy: 0.8406 - val_loss: 0.4109 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 6s 102us/sample - loss: 0.4410 - accuracy: 0.8458 - val_loss: 0.3977 - val_accuracy: 0.8620\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4299 - accuracy: 0.8489 - val_loss: 0.3917 - val_accuracy: 0.8652\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4128 - accuracy: 0.8558 - val_loss: 0.3829 - val_accuracy: 0.8666\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4012 - accuracy: 0.8589 - val_loss: 0.3761 - val_accuracy: 0.8686\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 6s 103us/sample - loss: 0.3932 - accuracy: 0.8625 - val_loss: 0.3706 - val_accuracy: 0.8712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcWhhEgi7so0",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Gradient Clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjhMyVNM7uJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
        "\n",
        "optimizer = keras.optimizers.SGD(clipnorm=1.0)\n",
        "\n",
        "#model.compile(loss=\"mse\", optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ov7Eid70kr",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyW4xHWuh4gk",
        "colab_type": "text"
      },
      "source": [
        "Using the fashion MNIST dataset, let's pretrain a network to classify 8 classes, then reuse parts of that network to perform binary classification on the remaining 2 classes.\n",
        "\n",
        "Let's start by splitting the dataset into two parts.\n",
        "\n",
        "*   ```X_train_A```: all classes except class 5 and 6 (sandals and shirts)\n",
        "*   ```X_train_B```: just the first 200 images of sandals and shirts.\n",
        "\n",
        "We also split the validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnDyX71M70Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]\n",
        "\n",
        "# reshape the inputs for CNN\n",
        "data = [X_train_A, X_valid_A, X_test_A, X_train_B, X_valid_B, X_test_B]\n",
        "for i in range(len(data)):\n",
        "  data[i].resize(*data[i].shape, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qic1Ic_L-sCp",
        "colab_type": "code",
        "outputId": "141ea673-dca5-4510-ac18-3000ce8ddbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_A.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43986, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYjWSCYS-uRU",
        "colab_type": "code",
        "outputId": "84038530-f032-4efd-e25c-688d2234c137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_B.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVimhQ5x-waf",
        "colab_type": "code",
        "outputId": "980f6be6-5033-4a30-fda2-0f6b1036eb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train_A[:30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
              "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d3jiztr-y0J",
        "colab_type": "code",
        "outputId": "4e6e3b95-9f47-4cda-ab3f-7097dc8fa508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train_B[:30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KYvj9WA-02u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "                       kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "\n",
        "model_A = keras.models.Sequential([\n",
        "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=128),\n",
        "    DefaultConv2D(filters=128),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=256),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation='relu'),\n",
        "    keras.layers.Dense(units=64, activation='relu'),\n",
        "    keras.layers.Dense(units=8, activation='softmax'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2OLss-2_aJM",
        "colab_type": "code",
        "outputId": "e6ae8f72-3ccb-400c-adc0-43611c2836b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=10, validation_data=[X_valid_A, y_valid_A])\n",
        "score = model_A.evaluate(X_test_A, y_test_A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 43986 samples, validate on 4014 samples\n",
            "Epoch 1/10\n",
            "43986/43986 [==============================] - 10s 236us/sample - loss: 0.7185 - accuracy: 0.7476 - val_loss: 0.4156 - val_accuracy: 0.8498\n",
            "Epoch 2/10\n",
            "43986/43986 [==============================] - 8s 191us/sample - loss: 0.3727 - accuracy: 0.8672 - val_loss: 0.3338 - val_accuracy: 0.8802\n",
            "Epoch 3/10\n",
            "43986/43986 [==============================] - 8s 191us/sample - loss: 0.3077 - accuracy: 0.8904 - val_loss: 0.2714 - val_accuracy: 0.9041\n",
            "Epoch 4/10\n",
            "43986/43986 [==============================] - 8s 191us/sample - loss: 0.2730 - accuracy: 0.9029 - val_loss: 0.2376 - val_accuracy: 0.9168\n",
            "Epoch 5/10\n",
            "43986/43986 [==============================] - 8s 188us/sample - loss: 0.2472 - accuracy: 0.9127 - val_loss: 0.2389 - val_accuracy: 0.9163\n",
            "Epoch 6/10\n",
            "43986/43986 [==============================] - 8s 187us/sample - loss: 0.2306 - accuracy: 0.9178 - val_loss: 0.2183 - val_accuracy: 0.9215\n",
            "Epoch 7/10\n",
            "43986/43986 [==============================] - 8s 186us/sample - loss: 0.2179 - accuracy: 0.9219 - val_loss: 0.2314 - val_accuracy: 0.9183\n",
            "Epoch 8/10\n",
            "43986/43986 [==============================] - 8s 186us/sample - loss: 0.2045 - accuracy: 0.9267 - val_loss: 0.2098 - val_accuracy: 0.9238\n",
            "Epoch 9/10\n",
            "43986/43986 [==============================] - 8s 187us/sample - loss: 0.1952 - accuracy: 0.9293 - val_loss: 0.2000 - val_accuracy: 0.9255\n",
            "Epoch 10/10\n",
            "43986/43986 [==============================] - 8s 187us/sample - loss: 0.1860 - accuracy: 0.9316 - val_loss: 0.1985 - val_accuracy: 0.9283\n",
            "8000/8000 [==============================] - 1s 81us/sample - loss: 0.2176 - accuracy: 0.9227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BSHBY6K2AFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_A.save(\"my_model_A.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu1zTIT72Kw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_B = keras.models.Sequential([\n",
        "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=128),\n",
        "    DefaultConv2D(filters=128),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=256),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation='relu'),\n",
        "    keras.layers.Dense(units=64, activation='relu'),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R6O-eRF3S5B",
        "colab_type": "code",
        "outputId": "4cbe3e80-5a1e-459d-9154-8a8d691c4dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=10, validation_data=[X_valid_B, y_valid_B])\n",
        "score = model_B.evaluate(X_test_B, y_test_B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200 samples, validate on 986 samples\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 1s 3ms/sample - loss: 0.6898 - accuracy: 0.4950 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 0s 630us/sample - loss: 0.6850 - accuracy: 0.5050 - val_loss: 0.6826 - val_accuracy: 0.5304\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 0s 593us/sample - loss: 0.6807 - accuracy: 0.5400 - val_loss: 0.6784 - val_accuracy: 0.7373\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 0s 619us/sample - loss: 0.6763 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 0.7414\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 0s 601us/sample - loss: 0.6716 - accuracy: 0.7550 - val_loss: 0.6689 - val_accuracy: 0.7110\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 0s 586us/sample - loss: 0.6660 - accuracy: 0.7950 - val_loss: 0.6631 - val_accuracy: 0.6714\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 0s 580us/sample - loss: 0.6595 - accuracy: 0.7500 - val_loss: 0.6562 - val_accuracy: 0.8763\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 0s 597us/sample - loss: 0.6514 - accuracy: 0.8600 - val_loss: 0.6467 - val_accuracy: 0.6653\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 0s 601us/sample - loss: 0.6410 - accuracy: 0.7800 - val_loss: 0.6346 - val_accuracy: 0.7708\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 0s 625us/sample - loss: 0.6273 - accuracy: 0.7800 - val_loss: 0.6212 - val_accuracy: 0.8895\n",
            "2000/2000 [==============================] - 0s 114us/sample - loss: 0.6219 - accuracy: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKkw6aCWx0u",
        "colab_type": "text"
      },
      "source": [
        "Load model A and replace the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvfmPpIX3dKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        "model_B_on_A = keras. models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRERkxzW5S_",
        "colab_type": "text"
      },
      "source": [
        "Because the layers for ```model_B_on_A``` are shared with ```model_A```, training performed on ```model_B_on_A``` will also affect ```model_A```. If  you want to avoid that, you can make a copy of ```model_A```, which will not be affected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EbAFK1ZWMTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blFYWQ0UXx9Y",
        "colab_type": "text"
      },
      "source": [
        "Let's freeze all of the reused layers first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccjm5vdMX5eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FULgo9dNX_mK",
        "colab_type": "code",
        "outputId": "1888123c-8822-46b3-fc9d-a28a496e9855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
        "                           validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200 samples, validate on 986 samples\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 1.1990 - accuracy: 0.5050 - val_loss: 1.0853 - val_accuracy: 0.5010\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 0s 514us/sample - loss: 1.0411 - accuracy: 0.5000 - val_loss: 0.9422 - val_accuracy: 0.5020\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 0s 513us/sample - loss: 0.9031 - accuracy: 0.5050 - val_loss: 0.8110 - val_accuracy: 0.5112\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 0s 531us/sample - loss: 0.7786 - accuracy: 0.5200 - val_loss: 0.7097 - val_accuracy: 0.5345\n",
            "Train on 200 samples, validate on 986 samples\n",
            "Epoch 1/16\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.5634 - accuracy: 0.6800 - val_loss: 0.3850 - val_accuracy: 0.8377\n",
            "Epoch 2/16\n",
            "200/200 [==============================] - 0s 611us/sample - loss: 0.3238 - accuracy: 0.8900 - val_loss: 0.2790 - val_accuracy: 0.9138\n",
            "Epoch 3/16\n",
            "200/200 [==============================] - 0s 589us/sample - loss: 0.2341 - accuracy: 0.9450 - val_loss: 0.2209 - val_accuracy: 0.9462\n",
            "Epoch 4/16\n",
            "200/200 [==============================] - 0s 587us/sample - loss: 0.1820 - accuracy: 0.9700 - val_loss: 0.1818 - val_accuracy: 0.9604\n",
            "Epoch 5/16\n",
            "200/200 [==============================] - 0s 614us/sample - loss: 0.1466 - accuracy: 0.9800 - val_loss: 0.1557 - val_accuracy: 0.9746\n",
            "Epoch 6/16\n",
            "200/200 [==============================] - 0s 589us/sample - loss: 0.1231 - accuracy: 0.9850 - val_loss: 0.1366 - val_accuracy: 0.9817\n",
            "Epoch 7/16\n",
            "200/200 [==============================] - 0s 594us/sample - loss: 0.1062 - accuracy: 0.9950 - val_loss: 0.1216 - val_accuracy: 0.9838\n",
            "Epoch 8/16\n",
            "200/200 [==============================] - 0s 602us/sample - loss: 0.0930 - accuracy: 0.9950 - val_loss: 0.1095 - val_accuracy: 0.9878\n",
            "Epoch 9/16\n",
            "200/200 [==============================] - 0s 590us/sample - loss: 0.0824 - accuracy: 0.9950 - val_loss: 0.1003 - val_accuracy: 0.9888\n",
            "Epoch 10/16\n",
            "200/200 [==============================] - 0s 630us/sample - loss: 0.0743 - accuracy: 0.9950 - val_loss: 0.0925 - val_accuracy: 0.9888\n",
            "Epoch 11/16\n",
            "200/200 [==============================] - 0s 587us/sample - loss: 0.0676 - accuracy: 0.9950 - val_loss: 0.0857 - val_accuracy: 0.9899\n",
            "Epoch 12/16\n",
            "200/200 [==============================] - 0s 603us/sample - loss: 0.0614 - accuracy: 0.9950 - val_loss: 0.0800 - val_accuracy: 0.9899\n",
            "Epoch 13/16\n",
            "200/200 [==============================] - 0s 594us/sample - loss: 0.0566 - accuracy: 0.9950 - val_loss: 0.0752 - val_accuracy: 0.9899\n",
            "Epoch 14/16\n",
            "200/200 [==============================] - 0s 592us/sample - loss: 0.0524 - accuracy: 0.9950 - val_loss: 0.0711 - val_accuracy: 0.9899\n",
            "Epoch 15/16\n",
            "200/200 [==============================] - 0s 618us/sample - loss: 0.0491 - accuracy: 0.9950 - val_loss: 0.0673 - val_accuracy: 0.9899\n",
            "Epoch 16/16\n",
            "200/200 [==============================] - 0s 594us/sample - loss: 0.0459 - accuracy: 0.9950 - val_loss: 0.0640 - val_accuracy: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eFj-P9cbPce",
        "colab_type": "code",
        "outputId": "4275733d-dc2c-402c-c6ee-1fb3e692506a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 83us/sample - loss: 0.6219 - accuracy: 0.8860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6219099011421204, 0.886]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux930hCPbRLo",
        "colab_type": "code",
        "outputId": "c8ea99cf-3d3c-4938-c845-cc156384a583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 101us/sample - loss: 0.0557 - accuracy: 0.9945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05565613985061645, 0.9945]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}